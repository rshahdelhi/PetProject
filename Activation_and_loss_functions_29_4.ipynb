{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCeUUERwQvQ7oOayAEwu+Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rshahdelhi/PetProject/blob/master/Activation_and_loss_functions_29_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Activation and loss functions\n",
        "\n",
        "In this task, you'll implement several ANN models with different activation functions. For each, use the cross-entropy loss function as the loss function. Specifically, do the following:\n",
        "\n",
        "Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the tanh activation function for each layer.\n",
        "\n",
        "Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the sigmoid activation function for each layer.\n",
        "\n",
        "Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the ReLU activation function for each layer.\n",
        "\n",
        "Compare the results of each model. Which activation function performed best?"
      ],
      "metadata": {
        "id": "54JmngoSE-VE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87mRed1mDnPb",
        "outputId": "2874553e-688a-4f0f-8edd-6c9e49bd181f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 3s 4ms/step - loss: 7.9488 - accuracy: 0.1174\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 8.0623 - accuracy: 0.0974\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1122 - accuracy: 0.0972\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1122 - accuracy: 0.0972\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 8.1122 - accuracy: 0.0972\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 8.1122 - accuracy: 0.0972\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 8.1122 - accuracy: 0.0972\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 8.1122 - accuracy: 0.0972\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 8.1117 - accuracy: 0.0972\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 8.1120 - accuracy: 0.0972\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 8.1117 - accuracy: 0.0972\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 8.1117 - accuracy: 0.0972\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 8.1117 - accuracy: 0.0972\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 8.1117 - accuracy: 0.0972\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 8.1120 - accuracy: 0.0972\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 8.1122 - accuracy: 0.0972\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 8.1122 - accuracy: 0.0972\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 8.1122 - accuracy: 0.0972\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 8.1122 - accuracy: 0.0972\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 8.1122 - accuracy: 0.0972\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8bc4e41f10>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "import warnings\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "(X_train, y_train), (X_test,y_test) = mnist.load_data()\n",
        "\n",
        "input_dim= 784 # 28 * 28\n",
        "output_dim = nb_classess =10\n",
        "batch_size = 128\n",
        "nb_epoch = 20\n",
        "\n",
        "X_train = X_train.reshape(60000, input_dim)\n",
        "X_test = X_test.reshape(10000, input_dim)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /=255\n",
        "\n",
        "\n",
        "Y_train = to_categorical(y_train, nb_classess)\n",
        "Y_test = to_categorical(y_test, nb_classess)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "#Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the tanh activation function for each layer.\n",
        "# The first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"tanh\"))\n",
        "# The second dense layer\n",
        "model.add(Dense(64, activation=\"tanh\"))\n",
        "# last layer is the output layer.\n",
        "model.add(Dense(10, activation=\"tanh\"))\n",
        "\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# setting verbose=1 prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuray:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnBAaz23GhHr",
        "outputId": "bd15095f-87a2-4730-ccbd-0dbd715fc65c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_24 (Dense)            (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109,386\n",
            "Trainable params: 109,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Test score: 8.034871101379395\n",
            "Test accuray: 0.0982000008225441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "#Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the sigmoid  activation function for each layer.\n",
        "# The first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"sigmoid\"))\n",
        "# The second dense layer\n",
        "model.add(Dense(64, activation=\"sigmoid\"))\n",
        "# The last layer is the output layer\n",
        "model.add(Dense(10, activation=\"sigmoid\"))\n",
        "model.compile(optimizer='sgd',loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)\n",
        "model.summary()\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuray:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmjM2lu7HrG8",
        "outputId": "c04816a3-9189-4d67-9c6c-c1fb39f42ca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 2.2838 - accuracy: 0.1725\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.2331 - accuracy: 0.3229\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 2.1742 - accuracy: 0.4689\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.0901 - accuracy: 0.5334\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.9680 - accuracy: 0.5895\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 1.8045 - accuracy: 0.6191\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.6180 - accuracy: 0.6507\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.4379 - accuracy: 0.6816\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.2819 - accuracy: 0.7061\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 1.1516 - accuracy: 0.7326\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.0440 - accuracy: 0.7538\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.9546 - accuracy: 0.7726\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.8797 - accuracy: 0.7911\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.8162 - accuracy: 0.8056\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.7620 - accuracy: 0.8177\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.7155 - accuracy: 0.8273\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.6754 - accuracy: 0.8365\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.6406 - accuracy: 0.8437\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.6102 - accuracy: 0.8503\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.5836 - accuracy: 0.8559\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_15 (Dense)            (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109,386\n",
            "Trainable params: 109,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Test score: 0.5584204196929932\n",
            "Test accuray: 0.8626999855041504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "#Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the ReLU  activation function for each layer.\n",
        "# The first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"ReLU\"))\n",
        "# The second dense layer\n",
        "model.add(Dense(64, activation=\"ReLU\"))\n",
        "# The last layer is the output layer\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "model.compile(optimizer='sgd',loss='categorical_hinge', metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)\n",
        "model.summary()\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuray:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXMG1P88Ht6q",
        "outputId": "fb822578-c6fd-4361-b320-137f913c02a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 3s 4ms/step - loss: 1.0187 - accuracy: 0.3054\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.9876 - accuracy: 0.5207\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.9159 - accuracy: 0.6079\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.7505 - accuracy: 0.6897\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.5538 - accuracy: 0.7810\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4176 - accuracy: 0.8561\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3351 - accuracy: 0.8795\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.2896 - accuracy: 0.8903\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.2615 - accuracy: 0.8974\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2426 - accuracy: 0.9024\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2286 - accuracy: 0.9060\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2174 - accuracy: 0.9090\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2084 - accuracy: 0.9121\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2009 - accuracy: 0.9143\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1946 - accuracy: 0.9158\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1888 - accuracy: 0.9187\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1838 - accuracy: 0.9201\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1791 - accuracy: 0.9221\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1749 - accuracy: 0.9238\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1709 - accuracy: 0.9255\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_21 (Dense)            (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109,386\n",
            "Trainable params: 109,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Test score: 0.16543547809123993\n",
            "Test accuray: 0.9276999831199646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compare**\n",
        "\n",
        "The highest accuracy in both training and test sets are achived using the ReLU function "
      ],
      "metadata": {
        "id": "stXc5u3-bzOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "#Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the tanh  activation function for each layer.\n",
        "# The first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"tanh\"))\n",
        "# The second dense layer\n",
        "model.add(Dense(64, activation=\"tanh\"))\n",
        "# The last layer is the output layer\n",
        "model.add(Dense(10, activation=\"tanh\"))\n",
        "model.compile(optimizer='sgd',loss='categorical_hinge', metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)\n",
        "model.summary()\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuray:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXgC7S7xePq0",
        "outputId": "0e2bf40b-4686-4a38-a503-8f6641cc83be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.7013 - accuracy: 0.7455\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4533 - accuracy: 0.8709\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3884 - accuracy: 0.8889\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3508 - accuracy: 0.8987\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3240 - accuracy: 0.9050\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3030 - accuracy: 0.9101\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2859 - accuracy: 0.9145\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2713 - accuracy: 0.9186\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2585 - accuracy: 0.9222\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2474 - accuracy: 0.9255\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2376 - accuracy: 0.9285\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2288 - accuracy: 0.9308\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2209 - accuracy: 0.9328\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2137 - accuracy: 0.9349\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2071 - accuracy: 0.9366\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2010 - accuracy: 0.9382\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1957 - accuracy: 0.9397\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1905 - accuracy: 0.9410\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1858 - accuracy: 0.9420\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1814 - accuracy: 0.9433\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_30 (Dense)            (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109,386\n",
            "Trainable params: 109,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Test score: 0.17971359193325043\n",
            "Test accuray: 0.9431999921798706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "#Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the sigmoid  activation function for each layer.\n",
        "# The first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"sigmoid\"))\n",
        "# The second dense layer\n",
        "model.add(Dense(64, activation=\"sigmoid\"))\n",
        "# The last layer is the output layer\n",
        "model.add(Dense(10, activation=\"sigmoid\"))\n",
        "model.compile(optimizer='sgd',loss='categorical_hinge', metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)\n",
        "model.summary()\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuray:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukL-YAT6e2UP",
        "outputId": "aef9a9d3-db4c-4885-fdba-e9600c7ed693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 1.0268 - accuracy: 0.2086\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.0043 - accuracy: 0.3362\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 1.0014 - accuracy: 0.4368\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.9991 - accuracy: 0.5144\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.9971 - accuracy: 0.5702\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.9953 - accuracy: 0.6128\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.9936 - accuracy: 0.6434\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.9921 - accuracy: 0.6665\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.9905 - accuracy: 0.6849\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.9890 - accuracy: 0.6982\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.9875 - accuracy: 0.7091\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.9860 - accuracy: 0.7164\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.9844 - accuracy: 0.7229\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.9828 - accuracy: 0.7279\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.9811 - accuracy: 0.7314\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.9794 - accuracy: 0.7355\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.9776 - accuracy: 0.7365\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.9756 - accuracy: 0.7386\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.9736 - accuracy: 0.7394\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.9715 - accuracy: 0.7404\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_33 (Dense)            (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109,386\n",
            "Trainable params: 109,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Test score: 0.9695430397987366\n",
            "Test accuray: 0.755299985408783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "#Implement a three-layer ANN model with 128, 64, and 10 neurons in the layers. Use the ReLU   activation function for each layer.\n",
        "# The first dense layer\n",
        "model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n",
        "# The second dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# The last layer is the output layer\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "model.compile(optimizer='sgd',loss='categorical_hinge', metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)\n",
        "model.summary()\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuray:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ihkrjd-lfmYT",
        "outputId": "e5dba4d8-9890-4807-cfe1-22e82f4ea6a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 1.0128 - accuracy: 0.2867\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.9877 - accuracy: 0.4948\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.9233 - accuracy: 0.5839\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.7884 - accuracy: 0.6569\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.6033 - accuracy: 0.7489\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4602 - accuracy: 0.8285\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3662 - accuracy: 0.8684\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3099 - accuracy: 0.8830\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2763 - accuracy: 0.8911\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2539 - accuracy: 0.8975\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2375 - accuracy: 0.9018\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2250 - accuracy: 0.9057\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2147 - accuracy: 0.9090\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2061 - accuracy: 0.9124\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1988 - accuracy: 0.9151\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1925 - accuracy: 0.9171\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1870 - accuracy: 0.9191\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1819 - accuracy: 0.9214\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1772 - accuracy: 0.9231\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1731 - accuracy: 0.9247\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_42 (Dense)            (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109,386\n",
            "Trainable params: 109,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Test score: 0.1671404391527176\n",
            "Test accuray: 0.9269000291824341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compare the results of each model with the result of the same model from the previous task. Which loss function performed best?**\n",
        "\n",
        "The highest accuracies in both the training and test sets are achived using the Relu function. Morover, all accuracies for all models are lower when we train our model using hinge loss in comparision to using cross entropy loss."
      ],
      "metadata": {
        "id": "c01pO4vYg7vT"
      }
    }
  ]
}